{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 基于PaddleSeg的遥感地块分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一、项目背景介绍\n",
    "遥感影像地块分割, 旨在对遥感影像进行像素级内容解析，对遥感影像中感兴趣的类别进行提取和分类，在城乡规划、防汛救灾等领域具有很高的实用价值，在工业界也受到了广泛关注。现有的遥感影像地块分割数据处理方法局限于特定的场景和特定的数据来源，且精度无法满足需求。因此在实际应用中，仍然大量依赖于人工处理，需要消耗大量的人力、物力、财力。本项目旨在衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果，利用人工智能技术，对多来源、多场景的异构遥感影像数据进行充分挖掘，打造高效、实用的算法，提高遥感影像的分析提取能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、数据介绍\n",
    "### [遥感影像分割——WHDLD](https://aistudio.baidu.com/aistudio/datasetdetail/55589/0)\n",
    "### 数据集背景\n",
    "WHDLD数据集  \n",
    "- 包含6种类型的遥感地物类型  \n",
    "- 提取自UC Merced  \n",
    "- 由武汉大学于2018年发布  \n",
    "\n",
    "### 数据集内容\n",
    "影像信息：  \n",
    "- image size: 256 * 256 * 3  \n",
    "- image number: 4940  \n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3d1cd30362ba41b8afa6729a5be44a00338c47c6615f49c680c68c226a7957f4)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8a995f72b4a14cd5a2d20912d69cf99117d6aad9cd6445c9a8a1f901d826c2b8)\n",
    "\n",
    "### 标注信息\n",
    "6类\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/67966da8ea174102a2f645f08b9be80497505773f1274d5494ce46aff8093b5a)\n",
    "\n",
    "### 来源\n",
    "[https://sites.google.com/view/zhouwx/dataset#h.p_hQS2jYeaFpV0](https://sites.google.com/view/zhouwx/dataset#h.p_hQS2jYeaFpV0)\n",
    "\n",
    "### 其他说明\n",
    "If you use WHDLD in any resulting publications, please cite the following works:\n",
    "Shao, Z.; Yang, K.; Zhou, W. Performance Evaluation of Single-Label and Multi-Label Remote Sensing Image Retrieval Using a Dense Labeling Dataset. Remote Sens. 2018, 10(6), 964.\n",
    "Shao, Z., Zhou, W., Deng, X., Zhang, M., & Cheng, Q. Multilabel Remote Sensing Image Retrieval Based on Fully Convolutional Network. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2020, 13, 318-328."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、模型介绍\n",
    "> References: [HardNet飞桨（Paddle）论文复现(By:Jordan2020)](https://aistudio.baidu.com/aistudio/projectdetail/1848242)\n",
    "\n",
    "**HarDNet**指的是Harmonic DenseNet: A low memory traffic network，其突出的特点就是低内存占用率。过去几年，随着更强的计算能力和更大的数据集，我们能够训练更加复杂的网络。对于实时应用，我们面临的问题是如何在提高计算效率的同时，降低功耗。在这种情况下，作者们提出了HarDNet在两者之间寻求最佳平衡。\n",
    "\n",
    "HarDNet可以用于图像分割、目标检测和语义分割，其架构是基于Densely Connected Network。在HarDNet中，作者提出了Harmonic Dense Bocks的概念。如下图所示，可以看到该网络就像多个谐波。HarDNet的全称就是Harmonic Densely Connected Network。  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e3faeaed2ba74b1f867b673607332114935ec29f37d6468b99f5a7a6682df1a8)  \n",
    "作者对每一层的MoC施加一个软约束，以设计一个低CIO网络模型，并合理增加MACs。如下图所示，避免使用MoC非常低的层，例如具有非常大输入/输出通道比的Conv1x1层。受Densely Connected Networks的启发，作者提出了Harmonic Densely Connected Network (HarD- Net) 。首先减少来自DenseNet的大部分层连接，以降低级联损耗。然后，通过增加层的通道宽度来平衡输入/输出通道比率。  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ef3d058b1e0c42b583d479366eb2011252a8a0af79d041e7b63ca80c6d6d1c04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、环境安装与数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. PaddleSeg的安装与环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# 安装paddleseg，当前版本为2.4.0\r\n",
    "!pip install -q paddleseg==2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data55589\r\n",
      "└── WHDLD\r\n",
      "    ├── Images\r\n",
      "    └── ImagesPNG\r\n",
      "\r\n",
      "3 directories\r\n"
     ]
    }
   ],
   "source": [
    "# 解压训练数据集与标记\r\n",
    "!unzip -oq /home/aistudio/data/data55589/WHDLD.zip -d data/data55589\r\n",
    "\r\n",
    "# 查看文件目录\r\n",
    "!tree data/data55589 -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3. EISeg标注数据演示\n",
    "> [EISeg官方文档](https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.2/contrib/EISeg)\n",
    "\n",
    "EISeg(Efficient Interactive Segmentation)是基于飞桨开发的一个高效智能的交互式分割标注软件。涵盖了高精度和轻量级等不同方向的高质量交互式分割模型，方便开发者快速实现语义及实例标签的标注，降低标注成本。 另外，将EISeg获取到的标注应用到PaddleSeg提供的其他分割模型进行训练，便可得到定制化场景的高精度模型，打通分割任务从数据标注到模型训练及预测的全流程。\n",
    "\n",
    "#### **模型准备**\n",
    "在使用EIseg前，请先下载模型参数。EISeg开放了在COCO+LVIS和大规模人像数据上训练的四个标注模型，满足通用场景和人像场景的标注需求。其中模型结构对应EISeg交互工具中的网络选择模块，用户需要根据自己的场景需求选择不同的网络结构和加载参数。  \n",
    "本项目选用的是[hrnet18_ocr64_cocolvis](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18_ocr64_cocolvis.pdparams)模型。\n",
    "| 模型类型 | 适用场景 | 模型结构 | 下载地址|\n",
    "| --- | --- | --- | ---|\n",
    "| **高精度模型**  | **适用于通用场景的图像标注。** | **HRNet18_OCR64** | **[hrnet18_ocr64_cocolvis](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18_ocr64_cocolvis.pdparams)** |\n",
    "| 轻量化模型  | 适用于通用场景的图像标注。 |HRNet18s_OCR48 | [hrnet18s_ocr48_cocolvis](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18s_ocr48_cocolvis.pdparams) |\n",
    "| 高精度模型  | 适用于人像标注场景。 |HRNet18_OCR64 | [hrnet18_ocr64_human](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18_ocr64_human.pdparams) |\n",
    "| 轻量化模型  | 适用于人像标注场景。 |HRNet18s_OCR48 | [hrnet18s_ocr48_human](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18s_ocr48_human.pdparams) |\n",
    "\n",
    "#### **安装使用**\n",
    "\n",
    "EISeg提供多种安装方式，其中使用[pip](#PIP)和[运行代码](#运行代码)方式可兼容Windows，Mac OS和Linux。为了避免环境冲突，推荐在conda创建的虚拟环境中安装。\n",
    "\n",
    "版本要求:\n",
    "\n",
    "* PaddlePaddle >= 2.1.0\n",
    "\n",
    "PaddlePaddle安装请参考[官网](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html)。\n",
    "\n",
    "这里使用pip安装方式：\n",
    "\n",
    "```shell\n",
    "pip install eiseg\n",
    "```\n",
    "pip会自动安装依赖。安装完成后命令行输入：\n",
    "```shell\n",
    "eiseg\n",
    "```\n",
    "即可运行软件。\n",
    "\n",
    "#### **使用**\n",
    "\n",
    "打开软件后，在对项目进行标注前，需要进行如下设置：\n",
    "\n",
    "1. **模型参数加载**\n",
    "\n",
    "   选择合适的网络，并加载对应的模型参数。目前在EISeg中，网络分为`HRNet18s_OCR48`和`HRNet18_OCR64`，并分别提供了人像和通用两种模型参数。在正确加载模型参数后，右下角状态栏会给予说明。若网络参数与模型参数不符，将会弹出警告，此时加载失败需重新加载。正确加载的模型参数会记录在`近期模型参数`中，可以方便切换，并且下次打开软件时自动加载退出时的模型参数。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/20493e7446454ea6bc3f7648009ead3b700c8690aaee43cebedf4d97bec7125b)\n",
    "\n",
    "2. **图像加载**\n",
    "\n",
    "   文件$\\to$打开图像/图像文件夹。当看到主界面图像正确加载，`数据列表`正确出现图像路径即可。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0475e4cbeb274e89a970b710f12dd2c84201903098ec40b3b6dcef4e02ba203a)\n",
    "\n",
    "3. **标签添加/加载**\n",
    "\n",
    "   添加/加载标签。可以通过`添加标签`新建标签，标签分为4列，分别对应像素值、说明、颜色和删除。新建好的标签可以通过`保存标签列表`保存为txt文件，其他合作者可以通过`加载标签列表`将标签导入。通过加载方式导入的标签，重启软件后会自动加载。  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/893d7ec1186a48678c3b18d21ef9dc7e07e0ce5381e94ce18e873530b630a04e)\n",
    "\n",
    "\n",
    "4. **自动保存设置**\n",
    "\n",
    "   在使用中可以将`自动保存`设置上，设定好文件夹即可，这样在使用时切换图像会自动将完成标注的图像进行保存。\n",
    "\n",
    "当设置完成后即可开始进行标注。  \n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4defd4610c914422b68dd78b42df807a08e54358ea4e41a3acfc8d3ff66e45f0)\n",
    "\n",
    "\n",
    "#### **动图演示**\n",
    "> 因为视频演示在这里放不上去，所以直接引用了官方文档的动图。\n",
    "\n",
    "![](https://user-images.githubusercontent.com/71769312/141130688-e1529c27-aba8-4bf7-aad8-dda49808c5c7.gif)\n",
    "\n",
    "#### **标注效果**\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ea4a91cedd94434d88496c57ca12477ac74e0e150e374d1491fb49115e397a44)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e7db243366364fffa35fd5d84646f4f7c1053a6f2751466fb16cc0a263d929f3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4. 构造数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **数据增强**\n",
    "对数据集中的数据提高对比度、饱和度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **修改数据集标签**\n",
    "数据集提供的标注是1-6，这里改为0-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4940/4940 [22:43<00:00,  3.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "from PIL import Image\r\n",
    "from tqdm import trange\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "relab_path = \"data/data55589/WHDLD/ImagesPNG_Relabel\"\r\n",
    "if not os.path.exists(relab_path):\r\n",
    "    os.mkdir(relab_path)  # 创建新标签的文件夹\r\n",
    "\r\n",
    "label_dir = 'data/data55589/WHDLD/ImagesPNG'\r\n",
    "label_dir_list = os.listdir(label_dir)\r\n",
    "for d in trange(len(label_dir_list)):\r\n",
    "    im = Image.open(os.path.join(label_dir,label_dir_list[d]))  # 打开图片\r\n",
    "    width = im.size[0]  # 获取宽度\r\n",
    "    height = im.size[1]  # 获取长度\r\n",
    "    im = np.array(im)\r\n",
    "    for x in range(width):\r\n",
    "        for y in range(height):\r\n",
    "            label_origin = im[x, y]  # 原坐标对应的标签\r\n",
    "            if (label_origin <= 6):\r\n",
    "                im[x, y] -= 1  # 1-6变为0-5\r\n",
    "            else:\r\n",
    "                print(label_origin)\r\n",
    "    new_im = Image.fromarray(im.astype(np.uint8), mode='P')\r\n",
    "    new_im.save(os.path.join(relab_path, label_dir_list[d]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **将训练集的图像集和标注路径写入datas中并抽样可视化**\n",
    "- 左：原图\n",
    "- 中：原标注\n",
    "- 右：修改后的标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 4940\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "import time\r\n",
    "import matplotlib.patches as mpatches\r\n",
    "\r\n",
    "datas = []\r\n",
    "image_base = 'data/data55589/WHDLD/Images'   # 训练集原图路径\r\n",
    "annos_base = 'data/data55589/WHDLD/ImagesPNG_Relabel'   # 训练集标签路径\r\n",
    "\r\n",
    "# 读取原图文件名\r\n",
    "ids_ = [v.split('.')[0] for v in os.listdir(image_base)]\r\n",
    "\r\n",
    "# 将训练集的图像集和标签路径写入datas中\r\n",
    "for id_ in ids_:\r\n",
    "    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))\r\n",
    "    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))\r\n",
    "    datas.append((img_pt0.replace('/home/aistudio', ''), img_pt1.replace('/home/aistudio', '')))\r\n",
    "    if os.path.exists(img_pt0) and os.path.exists(img_pt1):\r\n",
    "        pass\r\n",
    "    else:\r\n",
    "        raise Exception(\"path invalid!\")\r\n",
    "\r\n",
    "# 随机打乱datas\r\n",
    "np.random.seed(int(time.time()))\r\n",
    "np.random.shuffle(datas)\r\n",
    "\r\n",
    "# 打印datas的长度\r\n",
    "print('total:', len(datas))\r\n",
    "\r\n",
    "# 抽样可视化\r\n",
    "def visualize(path, i, title):\r\n",
    "    img = cv2.imread(path)[:, :, ::-1]\r\n",
    "    plt.subplot(len(datas[15]), 3, i)\r\n",
    "    plt.title(title)\r\n",
    "    plt.imshow(img)\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(10, 7))\r\n",
    "# 图例\r\n",
    "building = mpatches.Patch(color='red', label='Buildings')\r\n",
    "road = mpatches.Patch(color='yellow', label='Road')\r\n",
    "pavement = mpatches.Patch(color='darkkhaki', label='Pavement')\r\n",
    "vegetation = mpatches.Patch(color='lime', label='Vegetation')\r\n",
    "water = mpatches.Patch(color='mediumblue', label='Water')\r\n",
    "soil = mpatches.Patch(color='grey', label='Bare Soil')\r\n",
    "fig.legend(\r\n",
    "    handles=[building, road, pavement, vegetation, water, soil],\r\n",
    "    loc='upper center',\r\n",
    "    ncol=6\r\n",
    ")\r\n",
    "# 显示图片\r\n",
    "visualize(datas[15][0], 1, datas[15][0][-10:])\r\n",
    "visualize(os.path.join(\"data/data55589/WHDLD/ImagesPNG\", datas[15][1][-10:]), 2, datas[15][1][-10:])\r\n",
    "visualize(datas[15][1], 3, \"relabeled \" + datas[15][1][-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **将训练集、测试集图片路径写入txt文件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4446\n",
      "val: 493\n",
      "test: 1\n"
     ]
    }
   ],
   "source": [
    "# 四类标签\r\n",
    "labels = ['bare soil', 'building', 'pavement',  'road', 'vegetation', 'water']\r\n",
    "num_classes = 6\r\n",
    "\r\n",
    "# 将labels写入标签文件\r\n",
    "with open('data/labels.txt', 'w') as f:\r\n",
    "    for v in labels:\r\n",
    "        f.write(v + '\\n')\r\n",
    "\r\n",
    "# 验证集与训练集的划分\r\n",
    "split_num = int(0.1 * len(datas))  # 90%为训练集\r\n",
    "\r\n",
    "# 划分训练集、验证集和测试集\r\n",
    "train_data = datas[:-split_num]\r\n",
    "val_data = datas[-split_num:-1]\r\n",
    "test_data = datas[-1:]\r\n",
    "\r\n",
    "# 写入训练集list\r\n",
    "with open('data/train_list.txt', 'w') as f:\r\n",
    "    for img, lbl in train_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "# 写入验证集list\r\n",
    "with open('data/val_list.txt', 'w') as f:\r\n",
    "    for img, lbl in val_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "# 写入测试集list\r\n",
    "with open('data/test_list.txt', 'w') as f:\r\n",
    "    for img, lbl in test_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "# 打印训练集、验证集和测试集大小\r\n",
    "print('train:', len(train_data))\r\n",
    "print('val:', len(val_data))\r\n",
    "print('test:', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **构建训练集和验证集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddleseg.transforms as T\r\n",
    "from paddleseg.datasets import Dataset\r\n",
    "\r\n",
    "dataset_root = './'  # 数据集根目录\r\n",
    "train_path = 'data/train_list.txt'  # 训练集txt文件\r\n",
    "val_path = 'data/val_list.txt'  # 验证集txt文件\r\n",
    "\r\n",
    "# 定义训练时的transforms\r\n",
    "train_transforms = [\r\n",
    "    T.RandomHorizontalFlip(0.5),  # 随机水平翻转\r\n",
    "    T.RandomVerticalFlip(0.5),  # 随机垂直翻转\r\n",
    "    # T.RandomDistort(\r\n",
    "    #     brightness_range=0.2, brightness_prob=0.5,\r\n",
    "    #     contrast_range=0.2, contrast_prob=0.5,\r\n",
    "    #     saturation_range=0.2, saturation_prob=0.5,\r\n",
    "    #     hue_range=15, hue_prob=0.5),\r\n",
    "    T.Resize(target_size=(256, 256)),\r\n",
    "    T.Normalize()\r\n",
    "]\r\n",
    "# 定义验证时的transforms\r\n",
    "eval_transforms = [\r\n",
    "    T.Resize((256, 256)),\r\n",
    "    T.Normalize()\r\n",
    "]\r\n",
    "\r\n",
    "# 构建训练集\r\n",
    "train_dataset = Dataset(transforms = train_transforms,\r\n",
    "                  dataset_root = dataset_root,\r\n",
    "                  num_classes = num_classes,\r\n",
    "                  train_path = train_path,\r\n",
    "                  mode = 'train')\r\n",
    "# 构建验证集\r\n",
    "eval_dataset = Dataset(transforms = eval_transforms,\r\n",
    "                  dataset_root = dataset_root,\r\n",
    "                  num_classes = num_classes,\r\n",
    "                  val_path = val_path,\r\n",
    "                  mode = 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. 模型准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **构建模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-21 17:57:34 [INFO]\tLoading pretrained model from model/model.pdparams\n",
      "2022-03-21 17:57:34 [INFO]\tThere are 347/347 variables loaded into HarDNet.\n"
     ]
    }
   ],
   "source": [
    "from paddleseg.models import HarDNet\r\n",
    "from paddleseg.models import UNet\r\n",
    "\r\n",
    "# 设置迭代次数\r\n",
    "iters = 10000\r\n",
    "# 设置batch_size\r\n",
    "batch_size = 128\r\n",
    "# 选用HarDNet模型\r\n",
    "model = HarDNet(num_classes=num_classes, pretrained=\"model/model.pdparams\")\r\n",
    "\r\n",
    "# 选用UNet模型\r\n",
    "# model = UNet(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **构建优化器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import paddleseg\r\n",
    "\r\n",
    "# 设置学习率\r\n",
    "base_lr = 0.001\r\n",
    "lr = paddle.optimizer.lr.PolynomialDecay(\r\n",
    "    base_lr, \r\n",
    "    power=0.9, \r\n",
    "    decay_steps=iters, \r\n",
    "    end_lr=0\r\n",
    ")\r\n",
    "# 设置优化器\r\n",
    "optimizer = paddle.optimizer.Momentum(\r\n",
    "    lr, \r\n",
    "    parameters=model.parameters(), \r\n",
    "    momentum=0.9, \r\n",
    "    weight_decay=4.0e-5\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **构建损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddleseg.models.losses import CrossEntropyLoss\r\n",
    "\r\n",
    "# 使用交叉熵损失函数\r\n",
    "losses = {}\r\n",
    "losses['types'] = [CrossEntropyLoss()]\r\n",
    "losses['coef'] = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型训练\r\n",
    "from paddleseg.core import train\r\n",
    "train(\r\n",
    "    model=model,\r\n",
    "    train_dataset=train_dataset,\r\n",
    "    val_dataset=eval_dataset,\r\n",
    "    optimizer=optimizer,\r\n",
    "    save_dir='output',\r\n",
    "    iters=iters,\r\n",
    "    batch_size=batch_size,\r\n",
    "    save_interval=200,\r\n",
    "    log_iters=10,\r\n",
    "    num_workers=0,\r\n",
    "    losses=losses,\r\n",
    "    use_vdl=True\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型评估\r\n",
    "from paddleseg.core import evaluate\r\n",
    "evaluate(\r\n",
    "        model,\r\n",
    "        eval_dataset\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "经过10000次训练，mIOU可以达到0.69左右，Acc可达0.87左右。\n",
    "```\n",
    "2022-03-17 15:19:50 [INFO]\t[EVAL] #Images: 493 mIoU: 0.6923 Acc: 0.8736 Kappa: 0.8222 Dice: 0.8087\n",
    "2022-03-17 15:19:50 [INFO]\t[EVAL] Class IoU: \n",
    "[0.6245 0.6726 0.5249 0.8296 0.5456 0.9565]\n",
    "2022-03-17 15:19:50 [INFO]\t[EVAL] Class Acc: \n",
    "[0.7703 0.7968 0.68   0.9039 0.7765 0.9777]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3. 效果可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **构建模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddleseg.models import HarDNet\r\n",
    "model = HarDNet(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **创建transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddleseg.transforms as T\n",
    "transforms = T.Compose([\n",
    "    T.Resize(target_size=(256, 256)),\n",
    "    T.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **构建待预测的图像列表**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "def get_image_list(image_path):\r\n",
    "    '''\r\n",
    "    获取待预测图像\r\n",
    "    '''\r\n",
    "    valid_suffix = [\r\n",
    "        '.JPEG', '.jpeg', '.JPG', '.jpg', '.BMP', '.bmp', '.PNG', '.png'\r\n",
    "    ]\r\n",
    "    image_list = []\r\n",
    "    image_dir = None\r\n",
    "    if os.path.isfile(image_path):  # 传入参数为一张图片时\r\n",
    "        if os.path.splitext(image_path)[-1] in valid_suffix:\r\n",
    "            image_list.append(image_path)\r\n",
    "    elif os.path.isdir(image_path):  # 传入参数为含有多张图片的文件夹时\r\n",
    "        image_dir = image_path\r\n",
    "        for root, dirs, files in os.walk(image_path):\r\n",
    "            for f in files:\r\n",
    "                if os.path.splitext(f)[-1] in valid_suffix:\r\n",
    "                    image_list.append(os.path.join(root, f))\r\n",
    "    else:\r\n",
    "        raise FileNotFoundError(\r\n",
    "            '`--image_path` is not found. it should be an image file or a directory including images'\r\n",
    "        )\r\n",
    "\r\n",
    "    if len(image_list) == 0:\r\n",
    "        raise RuntimeError('There are not image file in `--image_path`')\r\n",
    "\r\n",
    "    return image_list, image_dir\r\n",
    "\r\n",
    "image_path = test_data[0][0]\r\n",
    "image_list, image_dir = get_image_list(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddleseg.core import predict\r\n",
    "\r\n",
    "# 自定义分割预测颜色\r\n",
    "custom_color = [\r\n",
    "    255, 0, 0,  # building(red)\r\n",
    "    255, 255, 0,  # road(yello)\r\n",
    "    192, 192, 0,  # pavement(darkkhaki)\r\n",
    "    0, 255, 0,  # vegetation(green)\r\n",
    "    128, 128, 128,   # bare soil(gray)\r\n",
    "    0, 0, 255  # water(blue)\r\n",
    "]\r\n",
    "\r\n",
    "predict(\r\n",
    "    model,\r\n",
    "    model_path='output/best_model/model.pdparams',\r\n",
    "    # model_path=\"model/model.pdparams\",  # 测试用\r\n",
    "    transforms=transforms,\r\n",
    "    image_list=image_list,\r\n",
    "    image_dir=image_dir,\r\n",
    "    save_dir='output/results',\r\n",
    "    custom_color=custom_color\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **预测效果**\n",
    "- 左：原图\n",
    "- 中：原标注图像\n",
    "- 右：伪彩色预测效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\r\n",
    "import matplotlib.patches as mpatches\r\n",
    "\r\n",
    "# 待可视化的图像列表\r\n",
    "img_list = [\r\n",
    "    test_data[0][0],\r\n",
    "    os.path.join(\"data/data55589/WHDLD/ImagesPNG\", (test_data[0][0][-10:-3] + \"png\")),\r\n",
    "    os.path.join(\"output/results/pseudo_color_prediction\", (test_data[0][0][-10:-3] + \"png\")),\r\n",
    "]\r\n",
    "\r\n",
    "# 可视化\r\n",
    "fig = plt.figure(figsize=(10, 7))\r\n",
    "# 图例\r\n",
    "building = mpatches.Patch(color='red', label='Buildings')\r\n",
    "road = mpatches.Patch(color='yellow', label='Road')\r\n",
    "pavement = mpatches.Patch(color='darkkhaki', label='Pavement')\r\n",
    "vegetation = mpatches.Patch(color='lime', label='Vegetation')\r\n",
    "water = mpatches.Patch(color='mediumblue', label='Water')\r\n",
    "soil = mpatches.Patch(color='grey', label='Bare Soil')\r\n",
    "fig.legend(\r\n",
    "    handles=[building, road, pavement, vegetation, water, soil],\r\n",
    "    loc='upper center',\r\n",
    "    ncol=6\r\n",
    ")\r\n",
    "# 拼接子图 左/中/右: 原图/原标注/伪彩色预测效果\r\n",
    "cnt = 0\r\n",
    "for i in img_list:\r\n",
    "    img = plt.imread(i)\r\n",
    "    plt.subplot(231 + cnt)  # 拼接子图\r\n",
    "    plt.title(i.split('/')[2] + \"/\" + i.split('/')[3])\r\n",
    "    plt.imshow(img)\r\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 七、总结\n",
    "本项目仅用来熟悉PaddleSeg使用流程，日后有机会会对模型进行进一步优化。\n",
    "\n",
    "- 作者：储氢合金M.H.\n",
    "- 山西农业大学本科生\n",
    "- 兴趣方向：计算机视觉，学习视觉SLAM与深度学习结合ing\n",
    "- 个人主页：\n",
    "\t- [GitHub](https://github.com/NEKOAKIKI)\n",
    "   - [Gitee](https://gitee.com/nekoakiki)\n",
    "\t- [飞桨AI Studio](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/771061)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
